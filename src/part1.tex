\chapter{Постановка задачи} \label{chapt1}

\section{Основные определения} \label{sect1_1}

%Мы можем сделать \textbf{жирный текст} и \textit{курсив}.
Пусть $G~=~(V, E)$ --- неориентированный граф с множеством вершин $V$ и множеством ребер $E$, $n$ - число вершин. Матрицу смежности невзвешенного графа будем обозначать $A~=~(a_{ij})$, где $a_{ij}~=~1$, если ребро $(v_i, v_j) \in E$ и $a_{ij}~=~0$ в противном случае. Для взвешенных графов будем хранить в этой матрице веса ребер: $a_{ij}~=~w(v_i, v_j)$.

Расстояние между вершинами в графе задается матрицей расстояний $D~=~(d_{ij})$, которую получают из определенным образом заданных мер близости $H~=~(h_{ij})$ с помощью преобразования
$$D~=~(h \textbf{1}^\intercal + \textbf{1} h^\intercal - H - H ^\intercal) /2, $$
где $h$ --- вектор-диагональ матрицы $H$.

В некоторых случаях вместо матрицы $H$ используют матрицу $H_0$, состоящую из логарифмов элементов матрицы $H$.


\begin{definition}
\emph{Метрикой на множестве} $X$ называется функция $d: X^2\rightarrow \mathbb{R}$ такая, что для любых $x,\ y,\ z \in X$ выполнены следующие утверждения:
\begin{enumerate}
\item $d(x,y) = 0$\ \ \  тогда и только тогда, когда $x=y$
\item $d(x,y) + d(x,z) - d(y,z) \ge 0$\ \ \  (неравенство треугольника)
\end{enumerate}
\end{definition}

Из этого определения следует, что для любых $x,\ y \in X$:

\begin{enumerate}
\item $d(x,y) = d(y,x)$\ \ \ (симметричность)
\item $d(x,y) \ge 0$\ \ \  (неотрицательность)
\end{enumerate}


Рассмотрим другой класс функций, которые широко применяются в теории графов и сетей, исследовании марковских процессов и анализе статистических моделей.

\begin{definition}
Пусть $X$ --- непустое множество и $\Sigma \in \mathbb{R}$. Функция $\sigma: X^2 \rightarrow \mathbb{R}$ называется $\Sigma$\emph{-proximity} на $A$, если для любых $x,\ y,\ z \in X$ выполняются следующие условия:
\begin{enumerate}
\item $\sum\limits_{t \in X} \sigma (x,t) = \Sigma$
\item $\sigma(x,y) + \sigma(x,z) - \sigma(y,z) \le \sigma(x,x)$,\ \  где при $z = y$ и $x \ne y$ неравенство строгое.
\end{enumerate}
\end{definition}

В работе \cite{chebotarev2013studying} было доказано, что между метриками и $\Sigma$-proximities на множестве $X$ существует взаимно однозначное соответствие.

\begin{definition}
Пусть $G$ - мультиграф с набором вершин $V$. Функция $d: V*V \rightarrow \mathbb{R}$ называется \emph{cutpoint addictive (bottleneck addictive, graph-geodetic)}, если $d(i,j)+d(j,k) = d(i,k)$ выполнено тогда и только тогда, когда в графе $G$ любой путь, соединяющий вершины $i$ и $k$, проходит через вершину $j$.
\end{definition}

\begin{definition}
Говорят, что матрица $S=(s_{ij}) \in \mathbb{R}^{n\times n}$ задает \emph{транзитивную меру} $s(i,j) = s_{ij}$ на вершинах $i,j \in V$ графа $G$, если ее элементы удовлетворяют транзитивному неравенству $$s_{ij}s_{jk} \le s_{ik}s_{jj}.$$

Это неравенство является аналогом неравенства треугольника для мер близости.
\end{definition}
\\
\textbf{Теорема}
Пусть $S=(s_{ij}) \in \mathbb{R}^{n\times n}$ задает транзитивную меру на графе $G$ и все недиагональные элементы этой матрицы положительны. Тогда матрица $D = (d_{ij})_{n\times n}$, определенная как
$$D~=~(h \textbf{1}^\intercal + \textbf{1} h^\intercal - H - H ^\intercal) /2,$$ 
где $H$ получается поэлементным логарифмированием матрицы $S$, является матрицей расстояний на $V(G)$. Более того, это расстояние будет cutpoint addictive.

Доказательство этой теоремы можно найти в \cite{von2014hitting}.


%\newpage
%============================================================================================================================

\section{Задача} \label{sect1_2}

Пусть $G$ --- случайный геометрический граф. Требуется исследовать поведение параметрических семейств графовых метрик на этом графе и найти оптимальные параметры, при которых метрики дают наиболее полную информацию о структуре графа $G$.

Также требуется сравнить поведение логарифмических и нелогарифмических метрик.

В данной работе рассматривались три класса случайных геометрических графов: $\varepsilon$-графы, графы ближайших соседей, графы с гауссовским распределением весов ребер. Параметр ($\varepsilon$ или количество соседей) выбирался таким образом, чтобы граф оказался связным с высокой вероятностью. Это делалось потому, что наибольший интерес для машинного обучения представляют именно связные графы.

Генерация графов происходила следующим образом: сначала случайным образом генерировались вершины (из равномерного распределения на $d$-мерном кубе и из смеси гауссовских распределений с различными параметрами смеси), затем по определенным правилам эти вершины соединялись ребрами. В случае $\varepsilon$-графов ребро $(v_i, v_j)$ добавлялось в том случае, если евклидово расстояние между этими вершинами не превышало $\varepsilon$. В графах ближайших соседей каждая вершина соединялась ребром с $k$ своими ближайшими соседями \todo{(TODO: у von Luxburg рассматривались 2 типа kNN-графов, symmetric и mutual)}. В гауссовских графах все вершины были соединены, а веса ребер определялись по формуле 
\begin{equation}
w_{ij} = \exp(-\frac{||v_i - v_j||^2} {\sigma^2} ),
\end{equation}
где параметр $\sigma > 0.$

Для полученных графов вычислялись различные метрики, затем они сравнивались между собой. Для сравнения использовались коэффициент корреляции с евклидовым расстоянием и матричные нормы для матрицы $D_{euclid} - D_{metrics}$.




%\newpage
%============================================================================================================================


\section{Исследуемые метрики} \label{sect1_3}
\begin{itemize}
\item[1.] \textbf{Walk distance}

Это параметрическое семейство строится с использованием меры близости 
\begin{equation}
H = (I - tA)^{-1},
\end{equation}
где параметр $0 < t < \rho ^{-1}$, $\rho$ --- спектральный радиус матрицы A. При предельных значениях параметра метрика сходится к shortest path distance и long walk distance. 

\item[2.] \textbf{Logarithmic walk distance}

Мера $H_0$ получается поэлементным логарифмированием матрицы $H$, определяющей Walk distance.

\item[3.] \textbf{e-walk distance}

Является модификацией Walk distance для взвешенных графов \todo{TODO}.

\item[4.] \textbf{Forest distance}

Данное семейство подробно описано в \cite{chebotarev2005duality}.

\emph{Rooted tree} --- связный ациклический граф, одна вершина в котором отмечена как корень. \emph{Rooted forest} --- граф, все связные компоненты которого являются rooted trees.

Рассмотрим взвешенный граф $G$. Обозначим за $w(G)$ произведение весов его ребер. Для графа без ребер $w(G) = 1$. Если $S$ --- набор графов, то $w(S) = \sum\limits_{G \in S} w(G)$.  В случае, когда $S$ --- пустое множество, $w(S) = 0$. Если множество $S$ состоит из невзвешенных графов, то $w(S) = |S|$.

Введем следующие обозначения: 

\begin{enumerate}
\item $F = F(G)$ - множество \todo{spanning?} spanning rooted forests графа $G$; 
\item $F_{i,j} = F_{i,j}(G)$- множество таких spanning rooted forests, что вершина $i$ принадлежит дереву с корнем $j$; 
\item $F_{i,j}^{(p)} = F_{i,j}^{(p)}(G)$ - подмножество таких spanning rooted forests множества $F_{i,j}$, которые содержат ровно $p$ ребер.
\end{enumerate}

Пусть 
$$f = w(F),\ \  f_{i,j} = w(F_{i,j}),\ \  f_{i,j}^{(p)} = w(F_{i,j}^{(p)}),$$ 
где $i,j \in V(G)$ и $0 \le p < n$.

Теперь рассмотрим матрицу $Q = (I + L)^{-1}$.

Согласно \emph{Matrix forest theorem}, такая матрица существует для любого взвешенного мультиграфа и ее элементы равны $q_{i,j} = f_{i,j}/f,\ \ i,\ j = 1,\ 2\ldots n$. Матрицу $Q$ можно рассматривать как меру близости. 

Добавим зависимость от параметра:

\begin{equation}
H = (I + tL) ^{-1}, 
\end{equation} 
где параметр $t > 0$, а $L$ --- лапласиан графа.

При $t \to \inf$ данная метрика сходится к resistance distance. Доказательство этого факта, а также интерпретацию метрики можно найти в \cite{chebotarev2012walk}.

\item[5.] \textbf{Logarithmic forest distance}

$H$ получена поэлементным логарифмированием матрицы близости для forest distance

\item[6.] \textbf{Communicability distance}

[6]

Communicability между вершинами $p$ и $q$ в графе $G$ - это взвешенная сумма всех блужданий, которые начинаются в $p$ и заканчиваются в $q$, при этом чем короче блуждание, тем больше его вес. Если $A$ - матрица смежности графа, то Communicability между вершинами $p$ и $q$ - это соответствующий элемент матрицы $e^{A}$. 

Данное определение имеет простую физическую интерпретацию. Рассмотрим граф как систему из шариков массой $m$, соединенных пружинами с константой $m \omega ^2$. Затем вся эта система погружается в жидкость с температурой $T$. Под воздействием температуры шарики начинают осциллировать.

Гамильтониан системы имеет следующий вид:

$H = \Sigma _i (\frac{p_i^2}{2m} + (K-k_i)\frac{m\omega ^2 x_i^2}{2}) + \frac{m \omega ^2}{2} \Sigma _{i,j : i<j } A_{ij} (x_i-x_j)^2 $

************See Estrada p2*****************************88 

$H = e^{tA}$, параметр $t > 0$

\item[7.] \textbf{Logarithmic communicability distance}

$H$ получена поэлементным логарифмированием матрицы близости для communicability distance

\item[8.] \textbf{Free energy distance}

Это семейство метрик, зависящее от параметра $\beta$, было рассмотрено в работе [7]. Расстояние вычисляется следующим образом:

$P^{ref} = D^{-1} A$, $D = diag(Ae)$

$W = P^{ref} ** e^{-\beta C}$, где $C$ - матрица кратчайших расстояний между вершинами графа $G$

$Z = (I-W)^{-1}$

$Z^h = Z * D_h^{-1}$, $D_h = diag(Z)$

$\Phi = -\frac{1}{\beta} \log Z^h$

$D^{FE} = (\Phi + \Phi ^T)/ 2$

Данное расстояние стремится к расстоянию кратчайшего пути при $\beta \rightarrow \infty$ и к commute time при $\beta \rightarrow 0^+$

\item[9.] \textbf{Shortest path distance}

Кратчайшим путем между двумя вершинами графа называют такой путь между этими вершинами, что сумма весов ребер, из которых он состоит, минимальна.

Существует несколько способов вычисления кратчайшего пути, в данной работе используется алгоритм Флойда - Уоршелла [8].

\item[10.] \textbf{Resistance distance}

Резисторное расстояние между двумя вершинами эквивалентно напряжению между соответствующими точками в электрической цепи, полученной из графа $G$ заменой ребер на резисторы, сопротивление которых совпадает с весом ребер. 

$D = (L + J)^{-1}$, где $L$ - лапласовская матрица, $J$ - матрица, все элементы которой равны $\frac {1}{n}$, гдк $n$ - число вершин

\item[11.] \textbf{Avrachenkov distance}

Данное семейство мер близости было предложено в [9.]. Оно возникло при исследовании способов решения задачи классификации с частичным привлечением учителя (semi-supervised classification), которые основаны на использовании графов. 

$H = (1 - a)(I - aD^{-\sigma}AD^{\sigma-1})^{-1}$, где $a = \frac {2}{2+\mu}$,  $\mu$ - параметр регуляризации, который позволяет регулировать баланс между точностью классификации и гладкостью классифицирующей функции. Параметр 
$\sigma$ позволяет использовать общую формулу для трех методов классификации с частичным привлечением учителя. При $\sigma = 1$ получаем метод, основанный на использовании стандартного лапласиана графа, $\sigma = 0.5$ - нормированного лапласиана,  случай $\sigma = 0$ соответствует PageRank.

$D$ - матрица степеней вершин. В случае взвешенных графов вычисляется как сумма весов ребер, инцидентных данной вершине.


\item[12.] \textbf{Logarithmic Avrachenkov distance}

Данная мера близости вычисляется с помощью поэлементного логарифмирования элементов матрицы $H$ для метрики Авранченкова. 

\end{itemize}

%\newpage
%============================================================================================================================

\section{Формулы} \label{sect1_4}


При использовании дробей формулы могут получаться очень высокие:
$$
  \frac{1}{\sqrt(2)+
  \displaystyle\frac{1}{\sqrt{2}+
  \displaystyle\frac{1}{\sqrt{2}+\cdots}}}
$$

В формулах можно использовать греческие буквы:
$$
\alpha\beta\gamma\delta\epsilon\varepsilon\zeta\eta\theta\vartheta\iota\kappa\lambda\\mu\nu\xi\pi\varpi\rho\varrho\sigma\varsigma\tau\upsilon\phi\varphi\chi\psi\omega\Gamma\Delta\Theta\Lambda\Xi\Pi\Sigma\Upsilon\Phi\Psi\Omega
$$

%\newpage
%============================================================================================================================

\subsection{Ненумерованные многострочные формулы} \label{subsect1_4_2}

Вот так можно написать две формулы, не нумеруя их, чтобы знаки равно были строго друг под другом:
\begin{eqnarray}
  f_W & = & \min \left( 1, \max \left( 0, \frac{W_{soil} / W_{max}}{W_{crit}} \right)  \right), \nonumber \\
  f_T & = & \min \left( 1, \max \left( 0, \frac{T_s / T_{melt}}{T_{crit}} \right)  \right), \nonumber
\end{eqnarray}

Можно использовать разные математические алфавиты:
\begin{eqnarray}
\mathcal{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber
\end{eqnarray}

Посмотрим на систему уравнений на примере аттрактора Лоренца:

$$
\left\{
  \begin{array}{rl}
    \dot x = & \sigma (y-x) \\
    \dot y = & x (r - z) - y \\
    \dot z = & xy - bz
  \end{array}
\right.
$$

А для вёрстки матриц удобно использовать многоточия:
$$
\left(
  \begin{array}{ccc}
  	a_{11} & \ldots & a_{1n} \\
  	\vdots & \ddots & \vdots \\
  	a_{n1} & \ldots & a_{nn} \\
  \end{array}
\right)
$$


%\newpage
%============================================================================================================================
\subsection{Нумерованные формулы} \label{subsect1_4_3}

А вот так пишется нумерованая формула:
\begin{equation}
  \label{eq:equation1}
  e = \lim_{n \to \infty} \left( 1+\frac{1}{n} \right) ^n
\end{equation}

Нумерованых формул может быть несколько:
\begin{equation}
  \label{eq:equation2}
  \lim_{n \to \infty} \sum_{k=1}^n \frac{1}{k^2} = \frac{\pi^2}{6}
\end{equation}

В последствии на формулы (\ref{eq:equation1}) и (\ref{eq:equation2}) можно ссылаться.

%\newpage
%============================================================================================================================

\clearpage
